//go:build go1.18
// +build go1.18

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator. DO NOT EDIT.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

package openai

import "io"

// APIClientCancelFineTuneOptions contains the optional parameters for the APIClient.CancelFineTune method.
type APIClientCancelFineTuneOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateChatCompletionOptions contains the optional parameters for the APIClient.CreateChatCompletion method.
type APIClientCreateChatCompletionOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateCompletionOptions contains the optional parameters for the APIClient.CreateCompletion method.
type APIClientCreateCompletionOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateEditOptions contains the optional parameters for the APIClient.CreateEdit method.
type APIClientCreateEditOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateEmbeddingOptions contains the optional parameters for the APIClient.CreateEmbedding method.
type APIClientCreateEmbeddingOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateFileOptions contains the optional parameters for the APIClient.CreateFile method.
type APIClientCreateFileOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateFineTuneOptions contains the optional parameters for the APIClient.CreateFineTune method.
type APIClientCreateFineTuneOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateImageEditOptions contains the optional parameters for the APIClient.CreateImageEdit method.
type APIClientCreateImageEditOptions struct {
	// An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited. Must
	// be a valid PNG file, less than 4MB, and have the same dimensions as image.
	Mask io.ReadSeekCloser
	// The number of images to generate. Must be between 1 and 10.
	N *int32
	// The format in which the generated images are returned. Must be one of url or b64_json.
	ResponseFormat *CreateImageEditRequestResponseFormat
	// The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
	Size *CreateImageEditRequestSize
	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

// APIClientCreateImageOptions contains the optional parameters for the APIClient.CreateImage method.
type APIClientCreateImageOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateImageVariationOptions contains the optional parameters for the APIClient.CreateImageVariation method.
type APIClientCreateImageVariationOptions struct {
	// The number of images to generate. Must be between 1 and 10.
	N *int32
	// The format in which the generated images are returned. Must be one of url or b64_json.
	ResponseFormat *CreateImageVariationRequestResponseFormat
	// The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
	Size *CreateImageVariationRequestSize
	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

// APIClientCreateModerationOptions contains the optional parameters for the APIClient.CreateModeration method.
type APIClientCreateModerationOptions struct {
	// placeholder for future optional parameters
}

// APIClientCreateTranscriptionOptions contains the optional parameters for the APIClient.CreateTranscription method.
type APIClientCreateTranscriptionOptions struct {
	// The language of the input audio. Supplying the input language in ISO-639-1 [https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes]
	// format will improve accuracy and latency.
	Language *string
	// An optional text to guide the model's style or continue a previous audio segment. The prompt [/docs/guides/speech-to-text/prompting]
	// should match the audio language.
	Prompt *string
	// The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
	ResponseFormat *string
	// The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values
	// like 0.2 will make it more focused and deterministic. If set to 0, the model will
	// use log probability [https://en.wikipedia.org/wiki/Log_probability] to automatically increase the temperature until certain
	// thresholds are hit.
	Temperature *float32
}

// APIClientCreateTranslationOptions contains the optional parameters for the APIClient.CreateTranslation method.
type APIClientCreateTranslationOptions struct {
	// An optional text to guide the model's style or continue a previous audio segment. The prompt [/docs/guides/speech-to-text/prompting]
	// should be in English.
	Prompt *string
	// The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
	ResponseFormat *string
	// The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values
	// like 0.2 will make it more focused and deterministic. If set to 0, the model will
	// use log probability [https://en.wikipedia.org/wiki/Log_probability] to automatically increase the temperature until certain
	// thresholds are hit.
	Temperature *float32
}

// APIClientDeleteFileOptions contains the optional parameters for the APIClient.DeleteFile method.
type APIClientDeleteFileOptions struct {
	// placeholder for future optional parameters
}

// APIClientDeleteModelOptions contains the optional parameters for the APIClient.DeleteModel method.
type APIClientDeleteModelOptions struct {
	// placeholder for future optional parameters
}

// APIClientDownloadFileOptions contains the optional parameters for the APIClient.DownloadFile method.
type APIClientDownloadFileOptions struct {
	// placeholder for future optional parameters
}

// APIClientListFilesOptions contains the optional parameters for the APIClient.ListFiles method.
type APIClientListFilesOptions struct {
	// placeholder for future optional parameters
}

// APIClientListFineTuneEventsOptions contains the optional parameters for the APIClient.ListFineTuneEvents method.
type APIClientListFineTuneEventsOptions struct {
	// Whether to stream events for the fine-tune job. If set to true, events will be sent as data-onlyserver-sent events
	// [https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format]as they
	// become available. The stream will terminate with adata: [DONE] message when
	// the job is finished (succeeded, cancelled, or failed).
	// If set to false, only events generated so far will be returned.
	Stream *bool
}

// APIClientListFineTunesOptions contains the optional parameters for the APIClient.ListFineTunes method.
type APIClientListFineTunesOptions struct {
	// placeholder for future optional parameters
}

// APIClientListModelsOptions contains the optional parameters for the APIClient.ListModels method.
type APIClientListModelsOptions struct {
	// placeholder for future optional parameters
}

// APIClientRetrieveFileOptions contains the optional parameters for the APIClient.RetrieveFile method.
type APIClientRetrieveFileOptions struct {
	// placeholder for future optional parameters
}

// APIClientRetrieveFineTuneOptions contains the optional parameters for the APIClient.RetrieveFineTune method.
type APIClientRetrieveFineTuneOptions struct {
	// placeholder for future optional parameters
}

// APIClientRetrieveModelOptions contains the optional parameters for the APIClient.RetrieveModel method.
type APIClientRetrieveModelOptions struct {
	// placeholder for future optional parameters
}

type ChatCompletionFunctions struct {
	// REQUIRED; The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum
	// length of 64.
	Name *string

	// The description of what the function does.
	Description *string

	// The parameters the functions accepts, described as a JSON Schema object. See the guide [/docs/guides/gpt/function-calling]
	// for examples, and the JSON Schema reference
	// [https://json-schema.org/understanding-json-schema/] for documentation about the format.
	Parameters map[string]any
}

type ChatCompletionRequestMessage struct {
	// REQUIRED; The role of the messages author. One of system, user, assistant, or function.
	Role *ChatCompletionRequestMessageRole

	// The contents of the message. content is required for all messages except assistant messages with function calls.
	Content *string

	// The name and arguments of a function that should be called, as generated by the model.
	FunctionCall *ChatCompletionRequestMessageFunctionCall

	// The name of the author of this message. name is required if role is function, and it should be the name of the function
	// whose response is in the content. May contain a-z, A-Z, 0-9, and underscores,
	// with a maximum length of 64 characters.
	Name *string
}

// ChatCompletionRequestMessageFunctionCall - The name and arguments of a function that should be called, as generated by
// the model.
type ChatCompletionRequestMessageFunctionCall struct {
	// The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always
	// generate valid JSON, and may hallucinate parameters not defined by your function
	// schema. Validate the arguments in your code before calling your function.
	Arguments *string

	// The name of the function to call.
	Name *string
}

type ChatCompletionResponseMessage struct {
	// REQUIRED; The role of the author of this message.
	Role *ChatCompletionResponseMessageRole

	// The contents of the message.
	Content *string

	// The name and arguments of a function that should be called, as generated by the model.
	FunctionCall *ChatCompletionResponseMessageFunctionCall
}

// ChatCompletionResponseMessageFunctionCall - The name and arguments of a function that should be called, as generated by
// the model.
type ChatCompletionResponseMessageFunctionCall struct {
	// The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always
	// generate valid JSON, and may hallucinate parameters not defined by your function
	// schema. Validate the arguments in your code before calling your function.
	Arguments *string

	// The name of the function to call.
	Name *string
}

type ChatCompletionStreamResponseDelta struct {
	// The contents of the chunk message.
	Content *string

	// The name and arguments of a function that should be called, as generated by the model.
	FunctionCall *ChatCompletionStreamResponseDeltaFunctionCall

	// The role of the author of this message.
	Role *ChatCompletionStreamResponseDeltaRole
}

// ChatCompletionStreamResponseDeltaFunctionCall - The name and arguments of a function that should be called, as generated
// by the model.
type ChatCompletionStreamResponseDeltaFunctionCall struct {
	// The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always
	// generate valid JSON, and may hallucinate parameters not defined by your function
	// schema. Validate the arguments in your code before calling your function.
	Arguments *string

	// The name of the function to call.
	Name *string
}

type Components1TmenyvSchemasCreatechatcompletionrequestPropertiesFunctionCallOneof1 struct {
	// REQUIRED; The name of the function to call.
	Name *string
}

type CreateChatCompletionRequest struct {
	// REQUIRED; A list of messages comprising the conversation so far. Example Python code [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb].
	Messages []*ChatCompletionRequestMessage

	// REQUIRED; ID of the model to use. See the model endpoint compatibility [/docs/models/model-endpoint-compatibility] table
	// for details on which models work with the Chat API.
	Model *CreateChatCompletionRequestModel

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far,
	// decreasing the model's likelihood to repeat the same line verbatim.
	// See more information about frequency and presence penalties. [/docs/api-reference/parameter-details]
	FrequencyPenalty *float32

	// Controls how the model responds to function calls. "none" means the model does not call a function, and responds to the
	// end-user. "auto" means the model can pick between an end-user or calling a
	// function. Specifying a particular function via {"name":\ "my_function"} forces the model to call that function. "none"
	// is the default when no functions are present. "auto" is the default if functions
	// are present.
	FunctionCall *CreateChatCompletionRequestFunctionCall

	// A list of functions the model may generate JSON inputs for.
	Functions []*ChatCompletionFunctions

	// Modify the likelihood of specified tokens appearing in the completion.
	// Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from
	// -100 to 100. Mathematically, the bias is added to the logits generated by the
	// model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase
	// likelihood of selection; values like -100 or 100 should result in a ban or
	// exclusive selection of the relevant token.
	LogitBias any

	// The maximum number of tokens [/tokenizer] to generate in the chat completion.
	// The total length of input tokens and generated tokens is limited by the model's context length. Example Python code
	// [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb] for counting tokens.
	MaxTokens *int32

	// How many chat completion choices to generate for each input message.
	N *int32

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing
	// the model's likelihood to talk about new topics.
	// See more information about frequency and presence penalties. [/docs/api-reference/parameter-details]
	PresencePenalty *float32

	// Up to 4 sequences where the API will stop generating further tokens.
	Stop *CreateChatCompletionRequestStop

	// If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events
	// [https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format] as they
	// become available, with the stream terminated by a data: [DONE] message.
	// Example Python code [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb].
	Stream *bool

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower
	// values like 0.2 will make it more focused and deterministic.
	// We generally recommend altering this or top_p but not both.
	Temperature *float32

	// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens
	// with top_p probability mass. So 0.1 means only the tokens comprising the top
	// 10% probability mass are considered.
	// We generally recommend altering this or temperature but not both.
	TopP *float32

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

// CreateChatCompletionRequestFunctionCall - Controls how the model responds to function calls. "none" means the model does
// not call a function, and responds to the end-user. "auto" means the model can pick between an end-user or calling a
// function. Specifying a particular function via {"name":\ "my_function"} forces the model to call that function. "none"
// is the default when no functions are present. "auto" is the default if functions
// are present.
type CreateChatCompletionRequestFunctionCall struct {
}

// CreateChatCompletionRequestModel - ID of the model to use. See the model endpoint compatibility [/docs/models/model-endpoint-compatibility]
// table for details on which models work with the Chat API.
type CreateChatCompletionRequestModel struct {
}

// CreateChatCompletionRequestStop - Up to 4 sequences where the API will stop generating further tokens.
type CreateChatCompletionRequestStop struct {
}

type CreateChatCompletionResponse struct {
	// REQUIRED
	Choices []*CreateChatCompletionResponseChoicesItem

	// REQUIRED
	Created *int32

	// REQUIRED
	ID *string

	// REQUIRED
	Model *string

	// REQUIRED
	Object *string
	Usage  *CreateChatCompletionResponseUsage
}

type CreateChatCompletionResponseChoicesItem struct {
	FinishReason *CreateChatCompletionResponseChoicesItemFinishReason
	Index        *int32
	Message      *ChatCompletionResponseMessage
}

type CreateChatCompletionResponseUsage struct {
	// REQUIRED
	CompletionTokens *int32

	// REQUIRED
	PromptTokens *int32

	// REQUIRED
	TotalTokens *int32
}

type CreateChatCompletionStreamResponse struct {
	// REQUIRED
	Choices []*CreateChatCompletionStreamResponseChoicesItem

	// REQUIRED
	Created *int32

	// REQUIRED
	ID *string

	// REQUIRED
	Model *string

	// REQUIRED
	Object *string
}

type CreateChatCompletionStreamResponseChoicesItem struct {
	Delta        *ChatCompletionStreamResponseDelta
	FinishReason *CreateChatCompletionStreamResponseChoicesItemFinishReason
	Index        *int32
}

type CreateCompletionRequest struct {
	// REQUIRED; ID of the model to use. You can use the List models [/docs/api-reference/models/list] API to see all of your
	// available models, or see our Model overview [/docs/models/overview] for descriptions of
	// them.
	Model *CreateCompletionRequestModel

	// REQUIRED; The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of
	// token arrays.
	// Note that is the document separator that the model sees during training, so if a prompt is not specified the model will
	// generate as if from the beginning of a new document.
	Prompt *CreateCompletionRequestPrompt

	// Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token).
	// Results cannot be streamed.
	// When used with n, best_of controls the number of candidate completions and n specifies how many to return â€“ best_of must
	// be greater than n.
	// Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure
	// that you have reasonable settings for max_tokens and stop.
	BestOf *int32

	// Echo back the prompt in addition to the completion
	Echo *bool

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far,
	// decreasing the model's likelihood to repeat the same line verbatim.
	// See more information about frequency and presence penalties. [/docs/api-reference/parameter-details]
	FrequencyPenalty *float32

	// Modify the likelihood of specified tokens appearing in the completion.
	// Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from
	// -100 to 100. You can use this tokenizer tool [/tokenizer?view=bpe] (which
	// works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated
	// by the model prior to sampling. The exact effect will vary per model, but values
	// between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or
	// exclusive selection of the relevant token.
	// As an example, you can pass {"50256": -100} to prevent the token from being generated.
	LogitBias any

	// Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is
	// 5, the API will return a list of the 5 most likely tokens. The API will always
	// return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.
	// The maximum value for logprobs is 5.
	Logprobs *int32

	// The maximum number of tokens [/tokenizer] to generate in the completion.
	// The token count of your prompt plus max_tokens cannot exceed the model's context length. Example Python code
	// [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb] for counting tokens.
	MaxTokens *int32

	// How many completions to generate for each prompt.
	// Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure
	// that you have reasonable settings for max_tokens and stop.
	N *int32

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing
	// the model's likelihood to talk about new topics.
	// See more information about frequency and presence penalties. [/docs/api-reference/parameter-details]
	PresencePenalty *float32

	// Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
	Stop *CreateCompletionRequestStop

	// Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events
	// [https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format] as they
	// become available, with the stream terminated by a data: [DONE] message.
	// Example Python code [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb].
	Stream *bool

	// The suffix that comes after a completion of inserted text.
	Suffix *string

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower
	// values like 0.2 will make it more focused and deterministic.
	// We generally recommend altering this or top_p but not both.
	Temperature *float32

	// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens
	// with top_p probability mass. So 0.1 means only the tokens comprising the top
	// 10% probability mass are considered.
	// We generally recommend altering this or temperature but not both.
	TopP *float32

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

// CreateCompletionRequestModel - ID of the model to use. You can use the List models [/docs/api-reference/models/list] API
// to see all of your available models, or see our Model overview [/docs/models/overview] for descriptions of
// them.
type CreateCompletionRequestModel struct {
}

// CreateCompletionRequestPrompt - The prompt(s) to generate completions for, encoded as a string, array of strings, array
// of tokens, or array of token arrays.
// Note that is the document separator that the model sees during training, so if a prompt is not specified the model will
// generate as if from the beginning of a new document.
type CreateCompletionRequestPrompt struct {
}

// CreateCompletionRequestStop - Up to 4 sequences where the API will stop generating further tokens. The returned text will
// not contain the stop sequence.
type CreateCompletionRequestStop struct {
}

type CreateCompletionResponse struct {
	// REQUIRED
	Choices []*CreateCompletionResponseChoicesItem

	// REQUIRED
	Created *int32

	// REQUIRED
	ID *string

	// REQUIRED
	Model *string

	// REQUIRED
	Object *string
	Usage  *CreateCompletionResponseUsage
}

type CreateCompletionResponseChoicesItem struct {
	// REQUIRED
	FinishReason *CreateCompletionResponseChoicesItemFinishReason

	// REQUIRED
	Index *int32

	// REQUIRED
	Logprobs *CreateCompletionResponseChoicesItemLogprobs

	// REQUIRED
	Text *string
}

type CreateCompletionResponseChoicesItemLogprobs struct {
	TextOffset    []*int32
	TokenLogprobs []*float32
	Tokens        []*string
	TopLogprobs   []any
}

type CreateCompletionResponseUsage struct {
	// REQUIRED
	CompletionTokens *int32

	// REQUIRED
	PromptTokens *int32

	// REQUIRED
	TotalTokens *int32
}

type CreateEditRequest struct {
	// REQUIRED; The instruction that tells the model how to edit the prompt.
	Instruction *string

	// REQUIRED; ID of the model to use. You can use the text-davinci-edit-001 or code-davinci-edit-001 model with this endpoint.
	Model *string

	// The input text to use as a starting point for the edit.
	Input *string

	// How many edits to generate for the input and instruction.
	N *int32

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower
	// values like 0.2 will make it more focused and deterministic.
	// We generally recommend altering this or top_p but not both.
	Temperature *float32

	// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens
	// with top_p probability mass. So 0.1 means only the tokens comprising the top
	// 10% probability mass are considered.
	// We generally recommend altering this or temperature but not both.
	TopP *float32
}

type CreateEditResponse struct {
	// REQUIRED
	Choices []*CreateEditResponseChoicesItem

	// REQUIRED
	Created *int32

	// REQUIRED
	Object *string

	// REQUIRED
	Usage *CreateEditResponseUsage
}

type CreateEditResponseChoicesItem struct {
	FinishReason *CreateEditResponseChoicesItemFinishReason
	Index        *int32
	Logprobs     *CreateEditResponseChoicesItemLogprobs
	Text         *string
}

type CreateEditResponseChoicesItemLogprobs struct {
	TextOffset    []*int32
	TokenLogprobs []*float32
	Tokens        []*string
	TopLogprobs   []any
}

type CreateEditResponseUsage struct {
	// REQUIRED
	CompletionTokens *int32

	// REQUIRED
	PromptTokens *int32

	// REQUIRED
	TotalTokens *int32
}

type CreateEmbeddingRequest struct {
	// REQUIRED; Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass
	// an array of strings or array of token arrays. Each input must not exceed the max input
	// tokens for the model (8191 tokens for text-embedding-ada-002). Example Python code [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb]
	// for counting
	// tokens.
	Input *CreateEmbeddingRequestInput

	// REQUIRED; ID of the model to use. You can use the List models [/docs/api-reference/models/list] API to see all of your
	// available models, or see our Model overview [/docs/models/overview] for descriptions of
	// them.
	Model *CreateEmbeddingRequestModel

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

// CreateEmbeddingRequestInput - Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in
// a single request, pass an array of strings or array of token arrays. Each input must not exceed the max input
// tokens for the model (8191 tokens for text-embedding-ada-002). Example Python code [https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb]
// for counting
// tokens.
type CreateEmbeddingRequestInput struct {
}

// CreateEmbeddingRequestModel - ID of the model to use. You can use the List models [/docs/api-reference/models/list] API
// to see all of your available models, or see our Model overview [/docs/models/overview] for descriptions of
// them.
type CreateEmbeddingRequestModel struct {
}

type CreateEmbeddingResponse struct {
	// REQUIRED
	Data []*CreateEmbeddingResponseDataItem

	// REQUIRED
	Model *string

	// REQUIRED
	Object *string

	// REQUIRED
	Usage *CreateEmbeddingResponseUsage
}

type CreateEmbeddingResponseDataItem struct {
	// REQUIRED
	Embedding []*float32

	// REQUIRED
	Index *int32

	// REQUIRED
	Object *string
}

type CreateEmbeddingResponseUsage struct {
	// REQUIRED
	PromptTokens *int32

	// REQUIRED
	TotalTokens *int32
}

type CreateFileRequest struct {
	// REQUIRED; Name of the JSON Lines [https://jsonlines.readthedocs.io/en/latest/] file to be uploaded.
	// If the purpose is set to "fine-tune", each line is a JSON record with "prompt" and "completion" fields representing your
	// training examples [/docs/guides/fine-tuning/prepare-training-data].
	File *io.ReadSeekCloser

	// REQUIRED; The intended purpose of the uploaded documents.
	// Use "fine-tune" for Fine-tuning [/docs/api-reference/fine-tunes]. This allows us to validate the format of the uploaded
	// file.
	Purpose *string
}

type CreateFineTuneRequest struct {
	// REQUIRED; The ID of an uploaded file that contains training data.
	// See upload file [/docs/api-reference/files/upload] for how to upload a file.
	// Your dataset must be formatted as a JSONL file, where each training example is a JSON object with the keys "prompt" and
	// "completion". Additionally, you must upload your file with the purpose fine-tune
	// .
	// See the fine-tuning guide [/docs/guides/fine-tuning/creating-training-data] for more details.
	TrainingFile *string

	// The batch size to use for training. The batch size is the number of training examples used to train a single forward and
	// backward pass.
	// By default, the batch size will be dynamically configured to be ~0.2% of the number of examples in the training set, capped
	// at 256 - in general, we've found that larger batch sizes tend to work better
	// for larger datasets.
	BatchSize *int32

	// If this is provided, we calculate F-beta scores at the specified beta values. The F-beta score is a generalization of F-1
	// score. This is only used for binary classification.
	// With a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger beta score puts more weight
	// on recall and less on precision. A smaller beta score puts more weight on
	// precision and less on recall.
	ClassificationBetas []*float32

	// The number of classes in a classification task.
	// This parameter is required for multiclass classification.
	ClassificationNClasses *int32

	// The positive class in binary classification.
	// This parameter is needed to generate precision, recall, and F1 metrics when doing binary classification.
	ClassificationPositiveClass *string

	// If set, we calculate classification-specific metrics such as accuracy and F-1 score using the validation set at the end
	// of every epoch. These metrics can be viewed in the results file
	// [/docs/guides/fine-tuning/analyzing-your-fine-tuned-model].
	// In order to compute classification metrics, you must provide avalidation_file. Additionally, you must specify classification_n_classes
	// for multiclass classification orclassification_positive_class for
	// binary classification.
	ComputeClassificationMetrics *bool

	// The learning rate multiplier to use for training. The fine-tuning learning rate is the original learning rate used for
	// pretraining multiplied by this value.
	// By default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final batch_size (larger learning rates
	// tend to perform better with larger batch sizes). We recommend experimenting with
	// values in the range 0.02 to 0.2 to see what produces the best results.
	LearningRateMultiplier *float32

	// The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie", "davinci", or a fine-tuned model
	// created after 2022-04-21. To learn more about these models, see theModels
	// [https://platform.openai.com/docs/models] documentation.
	Model *CreateFineTuneRequestModel

	// The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
	NEpochs *int32

	// The weight to use for loss on the prompt tokens. This controls how much the model tries to learn to generate the prompt
	// (as compared to the completion which always has a weight of 1.0), and can add a
	// stabilizing effect to training when completions are short.
	// If prompts are extremely long (relative to completions), it may make sense to reduce this weight so as to avoid over-prioritizing
	// learning the prompt.
	PromptLossWeight *float32

	// A string of up to 40 characters that will be added to your fine-tuned model name.
	// For example, a suffix of "custom-model-name" would produce a model name like ada:ft-your-org:custom-model-name-2022-02-15-04-21-04.
	Suffix *string

	// The ID of an uploaded file that contains validation data.
	// If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics
	// can be viewed in the fine-tuning results file
	// [/docs/guides/fine-tuning/analyzing-your-fine-tuned-model]. Your train and validation data should be mutually exclusive.
	// Your dataset must be formatted as a JSONL file, where each validation example is a JSON object with the keys "prompt" and
	// "completion". Additionally, you must upload your file with the purpose
	// fine-tune.
	// See the fine-tuning guide [/docs/guides/fine-tuning/creating-training-data] for more details.
	ValidationFile *string
}

// CreateFineTuneRequestModel - The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie",
// "davinci", or a fine-tuned model created after 2022-04-21. To learn more about these models, see theModels
// [https://platform.openai.com/docs/models] documentation.
type CreateFineTuneRequestModel struct {
}

type CreateImageEditRequest struct {
	// REQUIRED; The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have
	// transparency, which will be used as the mask.
	Image *io.ReadSeekCloser

	// REQUIRED; A text description of the desired image(s). The maximum length is 1000 characters.
	Prompt *string

	// An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited. Must
	// be a valid PNG file, less than 4MB, and have the same dimensions as image.
	Mask *io.ReadSeekCloser

	// The number of images to generate. Must be between 1 and 10.
	N *int32

	// The format in which the generated images are returned. Must be one of url or b64_json.
	ResponseFormat *CreateImageEditRequestResponseFormat

	// The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
	Size *CreateImageEditRequestSize

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

type CreateImageRequest struct {
	// REQUIRED; A text description of the desired image(s). The maximum length is 1000 characters.
	Prompt *string

	// The number of images to generate. Must be between 1 and 10.
	N *int32

	// The format in which the generated images are returned. Must be one of url or b64_json.
	ResponseFormat *CreateImageRequestResponseFormat

	// The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
	Size *CreateImageRequestSize

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

type CreateImageVariationRequest struct {
	// REQUIRED; The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
	Image *io.ReadSeekCloser

	// The number of images to generate. Must be between 1 and 10.
	N *int32

	// The format in which the generated images are returned. Must be one of url or b64_json.
	ResponseFormat *CreateImageVariationRequestResponseFormat

	// The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
	Size *CreateImageVariationRequestSize

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more [/docs/guides/safety-best-practices/end-user-ids].
	User *string
}

type CreateModerationRequest struct {
	// REQUIRED; The input text to classify
	Input *CreateModerationRequestInput

	// Two content moderations models are available: text-moderation-stable and text-moderation-latest.
	// The default is text-moderation-latest which will be automatically upgraded over time. This ensures you are always using
	// our most accurate model. If you use text-moderation-stable, we will provide
	// advanced notice before updating the model. Accuracy of text-moderation-stable may be slightly lower than for text-moderation-latest.
	Model *CreateModerationRequestModel
}

// CreateModerationRequestInput - The input text to classify
type CreateModerationRequestInput struct {
}

// CreateModerationRequestModel - Two content moderations models are available: text-moderation-stable and text-moderation-latest.
// The default is text-moderation-latest which will be automatically upgraded over time. This ensures you are always using
// our most accurate model. If you use text-moderation-stable, we will provide
// advanced notice before updating the model. Accuracy of text-moderation-stable may be slightly lower than for text-moderation-latest.
type CreateModerationRequestModel struct {
}

type CreateModerationResponse struct {
	// REQUIRED
	ID *string

	// REQUIRED
	Model *string

	// REQUIRED
	Results []*CreateModerationResponseResultsItem
}

type CreateModerationResponseResultsItem struct {
	// REQUIRED
	Categories *CreateModerationResponseResultsItemCategories

	// REQUIRED
	CategoryScores *CreateModerationResponseResultsItemCategoryScores

	// REQUIRED
	Flagged *bool
}

type CreateModerationResponseResultsItemCategories struct {
	// REQUIRED
	Hate *bool

	// REQUIRED
	HateThreatening *bool

	// REQUIRED
	SelfHarm *bool

	// REQUIRED
	Sexual *bool

	// REQUIRED
	SexualMinors *bool

	// REQUIRED
	Violence *bool

	// REQUIRED
	ViolenceGraphic *bool
}

type CreateModerationResponseResultsItemCategoryScores struct {
	// REQUIRED
	Hate *float32

	// REQUIRED
	HateThreatening *float32

	// REQUIRED
	SelfHarm *float32

	// REQUIRED
	Sexual *float32

	// REQUIRED
	SexualMinors *float32

	// REQUIRED
	Violence *float32

	// REQUIRED
	ViolenceGraphic *float32
}

type CreateTranscriptionRequest struct {
	// REQUIRED; The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav,
	// or webm.
	File *io.ReadSeekCloser

	// REQUIRED; ID of the model to use. Only whisper-1 is currently available.
	Model *CreateTranscriptionRequestModel

	// The language of the input audio. Supplying the input language in ISO-639-1 [https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes]
	// format will improve accuracy and latency.
	Language *string

	// An optional text to guide the model's style or continue a previous audio segment. The prompt [/docs/guides/speech-to-text/prompting]
	// should match the audio language.
	Prompt *string

	// The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
	ResponseFormat *string

	// The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values
	// like 0.2 will make it more focused and deterministic. If set to 0, the model will
	// use log probability [https://en.wikipedia.org/wiki/Log_probability] to automatically increase the temperature until certain
	// thresholds are hit.
	Temperature *float32
}

// CreateTranscriptionRequestModel - ID of the model to use. Only whisper-1 is currently available.
type CreateTranscriptionRequestModel struct {
}

type CreateTranscriptionResponse struct {
	// REQUIRED
	Text *string
}

type CreateTranslationRequest struct {
	// REQUIRED; The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or
	// webm.
	File *io.ReadSeekCloser

	// REQUIRED; ID of the model to use. Only whisper-1 is currently available.
	Model *CreateTranslationRequestModel

	// An optional text to guide the model's style or continue a previous audio segment. The prompt [/docs/guides/speech-to-text/prompting]
	// should be in English.
	Prompt *string

	// The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
	ResponseFormat *string

	// The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values
	// like 0.2 will make it more focused and deterministic. If set to 0, the model will
	// use log probability [https://en.wikipedia.org/wiki/Log_probability] to automatically increase the temperature until certain
	// thresholds are hit.
	Temperature *float32
}

// CreateTranslationRequestModel - ID of the model to use. Only whisper-1 is currently available.
type CreateTranslationRequestModel struct {
}

type CreateTranslationResponse struct {
	// REQUIRED
	Text *string
}

type DeleteFileResponse struct {
	// REQUIRED
	Deleted *bool

	// REQUIRED
	ID *string

	// REQUIRED
	Object *string
}

type DeleteModelResponse struct {
	// REQUIRED
	Deleted *bool

	// REQUIRED
	ID *string

	// REQUIRED
	Object *string
}

type Error struct {
	// REQUIRED
	Code *string

	// REQUIRED
	Message *string

	// REQUIRED
	Param *string

	// REQUIRED
	Type *string
}

type ErrorResponse struct {
	// REQUIRED
	Error *Error
}

// File - OpenAIFile
type File struct {
	// REQUIRED
	Bytes *int32

	// REQUIRED
	CreatedAt *int32

	// REQUIRED
	Filename *string

	// REQUIRED
	ID *string

	// REQUIRED
	Object *string

	// REQUIRED
	Purpose *string
	Status  *string

	// Anything
	StatusDetails any
}

// FineTune
type FineTune struct {
	// REQUIRED
	CreatedAt *int32

	// REQUIRED
	FineTunedModel *string

	// REQUIRED; Anything
	Hyperparams any

	// REQUIRED
	ID *string

	// REQUIRED
	Model *string

	// REQUIRED
	Object *string

	// REQUIRED
	OrganizationID *string

	// REQUIRED
	ResultFiles []*File

	// REQUIRED
	Status *string

	// REQUIRED
	TrainingFiles []*File

	// REQUIRED
	UpdatedAt *int32

	// REQUIRED
	ValidationFiles []*File
	Events          []*FineTuneEvent
}

// FineTuneEvent
type FineTuneEvent struct {
	// REQUIRED
	CreatedAt *int32

	// REQUIRED
	Level *string

	// REQUIRED
	Message *string

	// REQUIRED
	Object *string
}

type ImagesResponse struct {
	// REQUIRED
	Created *int32

	// REQUIRED
	Data []*ImagesResponseDataItem
}

type ImagesResponseDataItem struct {
	B64JSON *string
	URL     *string
}

type ListFilesResponse struct {
	// REQUIRED
	Data []*File

	// REQUIRED
	Object *string
}

type ListFineTuneEventsResponse struct {
	// REQUIRED
	Data []*FineTuneEvent

	// REQUIRED
	Object *string
}

type ListFineTunesResponse struct {
	// REQUIRED
	Data []*FineTune

	// REQUIRED
	Object *string
}

type ListModelsResponse struct {
	// REQUIRED
	Data []*Model

	// REQUIRED
	Object *string
}

// Model
type Model struct {
	// REQUIRED
	Created *int32

	// REQUIRED
	ID *string

	// REQUIRED
	Object *string

	// REQUIRED
	OwnedBy *string
}
